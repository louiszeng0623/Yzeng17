#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ç»ˆæç¨³æ€ç‰ˆï¼šä¸‰å±‚æ•°æ®æº
1) æ‡‚çƒå¸ App APIï¼ˆUA å¯é…ç½® + éšæœºå…œåº•ï¼Œè‡ªåŠ¨é‡è¯•ï¼Œç»“æ„è‡ªé€‚é…ï¼‰
2) æ‡‚çƒå¸çƒé˜Ÿç½‘é¡µï¼ˆHTML å†…åµŒ JSON é€’å½’æå–ï¼‰
3) ç›´æ’­å§ data ç«™çƒé˜Ÿé¡µï¼ˆHTML è¡¨æ ¼è§£æï¼‰
â†’ è‹¥æœ¬æ¬¡ä»å–ä¸åˆ°ï¼Œä¿ç•™æ—§ CSVï¼Œä¸æ¸…ç©ºï¼›ä¿å­˜ debug åŸå§‹å†…å®¹ä¾¿äºæ’æŸ¥ã€‚
"""

import os, re, csv, time, json, random, requests
from typing import List, Dict, Any, Iterable
from datetime import datetime, timedelta
from zoneinfo import ZoneInfo

# ===================== UA / åŸºç¡€é…ç½® =====================
DEFAULT_UAS = [
    "dongqiudiApp/7.1.0 (iPhone; iOS 17.5; Scale/3.00)",
    "dongqiudiApp/7.0.6 (iPhone; iOS 17.0.1; Scale/3.00)",
    "Mozilla/5.0 (iPhone; CPU iPhone OS 17_5 like Mac OS X) AppleWebKit/605.1.15 (KHTML, like Gecko) Mobile/15E148",
]
def pick_ua() -> str:
    ua_env = os.getenv("DQD_USER_AGENT", "").strip()
    return ua_env if ua_env else random.choice(DEFAULT_UAS)

def headers_json():
    return {
        "User-Agent": pick_ua(),
        "Referer": "https://m.dongqiudi.com/",
        "Accept": "application/json,text/plain,*/*",
        "Accept-Encoding": "gzip, deflate, br",
        "Connection": "keep-alive",
    }

def headers_html():
    return {
        "User-Agent": random.choice([
            "Mozilla/5.0 (iPhone; CPU iPhone OS 17_5 like Mac OS X) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/17.5 Mobile/15E148 Safari/604.1",
            "Mozilla/5.0 (Macintosh; Intel Mac OS X 14_5) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/17.5 Safari/605.1.15",
        ]),
        "Accept": "text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8",
        "Accept-Encoding": "gzip, deflate, br",
        "Connection": "keep-alive",
        "Referer": "https://www.dongqiudi.com/",
    }

# ===================== é˜Ÿä¼é…ç½®ï¼ˆå«ä¸‰ç§æ¥æºï¼‰ =====================
TEAMS = {
    "chengdu": {
        "name": "æˆéƒ½è“‰åŸ",
        "csv": "data/chengdu.csv",
        "api_id": "50016554",
        "dqd_page": "https://www.dongqiudi.com/team/50076899.html",
        "zb8_page": "https://data.zhibo8.cc/html/team.html?match=&team=%E6%88%90%E9%83%BD%E8%93%89%E5%9F%8E",
    },
    "inter": {
        "name": "å›½é™…ç±³å…°",
        "csv": "data/inter.csv",
        "api_id": "50001752",
        "dqd_page": "https://www.dongqiudi.com/team/50001042.html",
        "zb8_page": "https://data.zhibo8.cc/html/team.html?match=&team=%E5%9B%BD%E9%99%85%E7%B1%B3%E5%85%B0",
    },
}

API_URL_TPL = "https://api.dongqiudi.com/v3/team/schedule/list?team_id={team_id}"
MAX_RETRIES, RETRY_DELAY = 3, 5
CST = ZoneInfo("Asia/Shanghai")
PAST_DAYS, FUTURE_DAYS = 30, 365
FIELDS = ["date", "time_local", "opponent", "home_away", "competition", "stadium", "status"]

# ===================== å°å·¥å…· =====================
def save_debug(path: str, content: str | bytes):
    os.makedirs(os.path.dirname(path), exist_ok=True)
    mode = "wb" if isinstance(content, (bytes, bytearray)) else "w"
    with open(path, mode) as f:
        f.write(content)
    print(f"ğŸ“ debug ä¿å­˜ â†’ {path}")

def http_get(url: str, is_json=True) -> requests.Response | None:
    for i in range(1, MAX_RETRIES + 1):
        try:
            r = requests.get(url, headers=headers_json() if is_json else headers_html(), timeout=20)
            if r.status_code == 200:
                return r
            print(f"âš ï¸ HTTP {r.status_code}ï¼ˆç¬¬ {i}/{MAX_RETRIES} æ¬¡ï¼‰: {url}")
        except Exception as e:
            print(f"âŒ ç½‘ç»œå¼‚å¸¸ï¼š{e}ï¼ˆç¬¬ {i}/{MAX_RETRIES} æ¬¡ï¼‰: {url}")
        time.sleep(RETRY_DELAY)
    return None

# ===================== æ‡‚çƒå¸ï¼šAPI ç»“æ„è‡ªé€‚é… =====================
def api_pick_matches(payload: Any) -> List[Dict]:
    if not isinstance(payload, dict):
        return []
    if isinstance(payload.get("data"), list):
        return payload["data"]
    data = payload.get("data")
    if isinstance(data, dict):
        for k in ("matches", "list", "schedules"):
            v = data.get(k)
            if isinstance(v, list):
                return v
    for k in ("matches", "list", "schedules"):
        v = payload.get(k)
        if isinstance(v, list):
            return v
    return []

# ===================== æ‡‚çƒå¸ï¼šç½‘é¡µå›é€€ï¼ˆé€’å½’æŠ“å†…åµŒ JSONï¼‰ =====================
REQ_KEYS = {"start_play", "home_name", "away_name"}

def walk(obj: Any):
    if isinstance(obj, dict):
        if REQ_KEYS.issubset(obj.keys()):
            yield obj
        for v in obj.values():
            yield from walk(v)
    elif isinstance(obj, list):
        for it in obj:
            yield from walk(it)

def parse_dqd_html(html: str) -> List[Dict]:
    patterns = [
        r"__NUXT__\s*=\s*(\{.*?\});",
        r"window\.__INITIAL_STATE__\s*=\s*(\{.*?\});",
        r"window\.__NUXT__\s*=\s*(\{.*?\});",
    ]
    for pat in patterns:
        m = re.search(pat, html, flags=re.S | re.M)
        if m:
            raw = m.group(1)
            try:
                data = json.loads(raw)
                found = list(walk(data))
                if found:
                    print(f"ğŸ” DQD HTML æå– {len(found)} æ¡ï¼ˆvia {pat}ï¼‰")
                    return found
            except Exception:
                pass

    # å…œåº•ï¼šæ‰¾å° JSON å—
    found = []
    for s in re.findall(r"\{[^{}]*\}", html):
        if all(k in s for k in ["start_play", "home_name", "away_name"]):
            try:
                found.append(json.loads(s))
            except Exception:
                pass
    if found:
        print(f"ğŸ” DQD HTML å…œåº•æå– {len(found)} æ¡")
    return found

# ===================== ç›´æ’­å§ï¼šç½‘é¡µè¡¨æ ¼è§£æ =====================
def strip_tags(x: str) -> str:
    return re.sub(r"<[^>]+>", "", x or "").strip()

def parse_zb8_html(html: str, team_name: str) -> List[Dict]:
    """
    ç›´æ’­å§ data ç«™çš„ team.html é€šå¸¸æ˜¯è¡¨æ ¼ç»“æ„ï¼š
    æ—¥æœŸ/æ—¶é—´/èµ›äº‹/ä¸»é˜Ÿ/æ¯”åˆ†/å®¢é˜Ÿ/â€¦  è¿™é‡Œç”¨æ­£åˆ™æå– <tr> è¡Œâ†’<td> åˆ—ï¼Œå°½é‡å®½æ¾å…¼å®¹ã€‚
    """
    rows: List[Dict] = []

    # é€è¡Œæå– <tr>â€¦</tr>
    for tr in re.findall(r"<tr[^>]*>(.*?)</tr>", html, flags=re.S | re.I):
        tds = re.findall(r"<td[^>]*>(.*?)</td>", tr, flags=re.S | re.I)
        if len(tds) < 5:
            continue

        # ç²—ç•¥åˆ—ä½ï¼šæ—¥æœŸã€æ—¶é—´/èµ›äº‹ã€ä¸»é˜Ÿã€æ¯”åˆ†ã€å®¢é˜Ÿï¼ˆä¸åŒæ¨¡æ¿ä¼šæœ‰åç§»ï¼Œè¿™é‡Œåšå®¹é”™ï¼‰
        raw = [strip_tags(td) for td in tds]
        text = " | ".join(raw)

        # æŠ“æ—¥æœŸ/æ—¶é—´ï¼ˆYYYY-MM-DD, HH:MMï¼‰
        m_date = re.search(r"(\d{4}-\d{1,2}-\d{1,2})", text)
        m_time = re.search(r"(\d{1,2}:\d{2})", text)
        if not m_date:
            continue
        date = m_date.group(1)
        time_local = m_time.group(1) if m_time else "20:00"

        # ä¸»é˜Ÿ/å®¢é˜Ÿï¼ˆåœ¨ä¸€è¡Œé‡Œæ‰¾æœ€åƒçƒé˜Ÿåçš„ä¸¤ä¸ªè¯ï¼‰
        # å…ˆå°è¯•å¸¸è§„å¸ƒå±€ï¼š â€¦ | ä¸»é˜Ÿ | æ¯”åˆ† | å®¢é˜Ÿ |
        home, away = None, None
        if len(raw) >= 5:
            home = raw[-3]
            away = raw[-1]
        # å›é€€ï¼šåœ¨æ•´è¡Œé‡Œå®šä½ team_name å‡ºç°ä½ç½®ï¼Œå·¦å³å„å–ä¸€ä¸ªè¿‘ä¼¼é˜Ÿå
        if team_name not in (home or "") and team_name not in (away or ""):
            # ç®€åŒ–ï¼šå¦‚æœæ•´è¡ŒåŒ…å« team_nameï¼Œå°±æŠŠå¦ä¸€ä¸ªå½“å¯¹æ‰‹
            if team_name in text:
                # ä»å¯èƒ½çš„é˜Ÿååˆ—ä¸­æŒ‘é€‰
                candidates = [w for w in raw if 1 <= len(w) <= 20]
                # é€‰ä¸€ä¸ªé team_name çš„ä½œä¸º opponent
                opponent = None
                for w in candidates:
                    if team_name not in w and re.search(r"[\u4e00-\u9fa5A-Za-z]", w):
                        opponent = w
                        break
                if opponent:
                    # æ— æ³•åˆ¤æ–­ä¸»å®¢ï¼Œå°±é»˜è®¤â€œæœªçŸ¥â†’æŒ‰å®¢åœºå¤„ç†â€
                    home_away = "Home" if random.random() < 0.5 else "Away"
                    comp = ""
                    stadium = ""
                    rows.append({
                        "date": date, "time_local": time_local,
                        "opponent": opponent, "home_away": home_away,
                        "competition": comp, "stadium": stadium, "status": ""
                    })
                continue

        if not home or not away:
            continue

        # èµ›äº‹
        comp = ""
        for cell in raw:
            if "æ¯" in cell or "ç”²" in cell or "è”" in cell or "è¶…" in cell:
                comp = cell
                break

        # åˆ¤æ–­ä¸»å®¢
        if team_name in home:
            opponent = away
            home_away = "Home"
        elif team_name in away:
            opponent = home
            home_away = "Away"
        else:
            # è¡Œé‡Œæ²¡æœ‰è¯¥é˜Ÿåï¼Œè·³è¿‡
            continue

        rows.append({
            "date": date, "time_local": time_local,
            "opponent": opponent, "home_away": home_away,
            "competition": comp, "stadium": "", "status": ""
        })

    print(f"ğŸ” ZB8 HTML è§£æ {len(rows)} æ¡")
    return rows

# ===================== å½’ä¸€åŒ–ï¼ˆDQDæ¥æºï¼‰ =====================
def normalize_row(item: Dict, team_name: str) -> Dict | None:
    # æ—¶é—´
    ts = None
    if isinstance(item.get("start_play"), (int, float)):
        ts = int(item["start_play"])
    else:
        mt = item.get("match_time")
        if isinstance(mt, str):
            try:
                dt_try = datetime.fromisoformat(mt.replace("Z", "+00:00"))
                ts = int(dt_try.timestamp())
            except Exception:
                pass
        elif isinstance(mt, (int, float)):
            ts = int(mt)
    if not ts:
        return None
    dt = datetime.fromtimestamp(ts, tz=CST)

    # ä¸»å®¢åˆ¤æ–­
    home = item.get("home_name") or item.get("home") or ""
    away = item.get("away_name") or item.get("away") or ""
    is_home = item.get("is_home")
    if is_home is None:
        if home and team_name in str(home):
            is_home = True
        elif away and team_name in str(away):
            is_home = False
        else:
            return None

    opponent = away if is_home else home
    comp = item.get("competition_name") or item.get("competition") or ""
    stadium = item.get("stadium_name") or item.get("stadium") or ""

    status_name = (item.get("status_name") or item.get("status") or "").strip()
    if status_name in ("å»¶æœŸ", "æ¨è¿Ÿ", "æš‚åœ"):
        tag = "âš ï¸æ¯”èµ›å»¶æœŸ"
    elif status_name in ("å–æ¶ˆ",):
        tag = "âŒæ¯”èµ›å–æ¶ˆ"
    elif status_name in ("å¾…å®š", "æœªå¼€èµ›", "æ—¶é—´å¾…å®š"):
        tag = "ğŸ•“æ—¶é—´å¾…å®š"
    elif status_name in ("å®Œåœº", "å·²ç»“æŸ"):
        tag = "âœ…å®Œåœº"
    else:
        tag = ""

    return {
        "date": dt.strftime("%Y-%m-%d"),
        "time_local": dt.strftime("%H:%M"),
        "opponent": opponent,
        "home_away": "Home" if is_home else "Away",
        "competition": comp,
        "stadium": stadium,
        "status": tag,
        "_dt": dt,
    }

# ===================== ä¸»æµç¨‹ï¼ˆAPI â†’ DQD HTML â†’ ZB8 HTMLï¼‰ =====================
def fetch_team(team_key: str, api_id: str | None, dqd_page: str | None, zb8_page: str | None, team_name: str) -> List[Dict]:
    now = datetime.now(CST)
    start = (now - timedelta(days=PAST_DAYS)).replace(hour=0, minute=0, second=0, microsecond=0)
    end   = (now + timedelta(days=FUTURE_DAYS)).replace(hour=23, minute=59, second=59, microsecond=0)

    raw_list: List[Dict] = []

    # 1) DQD API
    if api_id:
        api_url = API_URL_TPL.format(team_id=api_id)
        print(f"\nğŸ“¡ {team_name} APIï¼š{api_url}")
        r = http_get(api_url, is_json=True)
        if r and r.status_code == 200:
            try:
                js = r.json()
                raw_list = api_pick_matches(js)
            except Exception as e:
                print("API JSON è§£æå¤±è´¥ï¼š", e)
        if not raw_list and r is not None:
            save_debug(f"data/debug_{team_key}.json", r.text)

    # 2) DQD HTML
    if not raw_list and dqd_page:
        print(f"ğŸª‚ DQD å›é€€ï¼š{dqd_page}")
        hr = http_get(dqd_page, is_json=False)
        if hr and hr.status_code == 200 and hr.text:
            save_debug(f"data/debug_{team_key}_dqd.html", hr.text[:200000].encode("utf-8", "ignore"))
            raw_list = parse_dqd_html(hr.text)

    # 3) ZB8 HTML
    zb8_rows: List[Dict] = []
    if not raw_list and zb8_page:
        print(f"ğŸª‚ ZB8 å›é€€ï¼š{zb8_page}")
        zr = http_get(zb8_page, is_json=False)
        if zr and zr.status_code == 200 and zr.text:
            save_debug(f"data/debug_{team_key}_zb8.html", zr.text[:200000].encode("utf-8", "ignore"))
            zb8_rows = parse_zb8_html(zr.text, team_name)

    # è‹¥æŠ“åˆ°çš„æ˜¯ DQD ç»“æ„ï¼Œç»§ç»­å½’ä¸€åŒ–ï¼›è‹¥æ˜¯ ZB8 è¡Œåˆ™ç›´æ¥ç”¨
    rows: List[Dict] = []
    if raw_list:
        for it in raw_list:
            row = normalize_row(it, team_name)
            if not row:
                continue
            if not (start <= row["_dt"] <= end):
                continue
            rows.append(row)
        # å»æ‰å†…éƒ¨å­—æ®µ
        for r0 in rows:
            r0.pop("_dt", None)
    else:
        rows = zb8_rows

    # å»é‡ + æ’åº
    rows.sort(key=lambda x: (x["date"], x["time_local"], x["opponent"], x["competition"]))
    out, seen = [], set()
    for r0 in rows:
        key = (r0["date"], r0["time_local"], r0["opponent"], r0["competition"])
        if key in seen:
            continue
        seen.add(key)
        out.append(r0)

    print(f"âœ… æœ€ç»ˆå¯ç”¨æ¡æ•°ï¼š{len(out)}")
    return out

# ===================== CSV ä¸å…œåº• =====================
def write_csv(path: str, rows: List[Dict]):
    os.makedirs(os.path.dirname(path), exist_ok=True)
    with open(path, "w", newline="", encoding="utf-8") as f:
        w = csv.DictWriter(f, fieldnames=FIELDS)
        w.writeheader()
        w.writerows(rows)
    print(f"ğŸ’¾ å†™å…¥ {len(rows)} æ¡ â†’ {path}")

def preserve_old_if_empty(path: str, new_rows: List[Dict]) -> bool:
    if new_rows:
        return False
    if os.path.exists(path) and os.path.getsize(path) > 0:
        print(f"ğŸ›Ÿ æ–°æ•°æ®ä¸ºç©ºï¼Œä¿ç•™æ—§æ–‡ä»¶ï¼š{path}")
        return True
    return False

def main():
    total = 0
    for key, info in TEAMS.items():
        rows = fetch_team(
            team_key=key,
            api_id=info.get("api_id"),
            dqd_page=info.get("dqd_page"),
            zb8_page=info.get("zb8_page"),
            team_name=info["name"],
        )
        if preserve_old_if_empty(info["csv"], rows):
            continue
        write_csv(info["csv"], rows)
        total += len(rows)
    print(f"\nğŸ¯ æœ¬æ¬¡å¯å†™å…¥æ€»è®¡ {total} æ¡ã€‚")

if __name__ == "__main__":
    main()
    
